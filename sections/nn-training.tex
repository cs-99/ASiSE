\section{Neural Network Training}
\label{training}
As an important part of creating a (feed-forward) NN is its training, it is briefly explained in this section. To begin with, sufficient training data needs to be available, in that there must exist a set of inputs to the network with the corresponding correct output for those inputs. 
Moreover, since only training by feeding data forward through the network does not lead to acceptable results, \emph{backpropagation} still generally is the main method for training NNs. As an example, Wilamoski et al. \cite{Wilamowski2010} proposed a method which was way quicker in the training process, but did not yield satisfactory outcomes. The results could be improved by increasing the number of neurons, however, this lead to the network being \emph{overtrained}, which means that the network performed well on data it had trained on, but could not handle new inputs (which were not part of the training) correctly.

\subsection{Backpropagation}
Since backpropagation itself is just a way to calculate derivatives, there are other applications than NNs. In most cases a simpler version of backpropagation is used for NNs, as proposed by Werbos et al. \cite{Werbos1990}, as it would require a lot of manual mathematics which can not be translated to executable code easily. Moreover, the derivatives would be highly dependent on the application itself and therefore could not be reused.\\
The general idea is to propagate the test input through the network to receive an output, which is then compared with the correct output of the training case. This comparison is done via a so-called \emph{loss function}. Just like with the activation function (see \autoref{neuron}), there exist numerous different versions. Once the loss has been determined, its derivative with respect to the parameter in the network (e.g. weight, bias) calculated. For this to work, every activation function, as well as the loss function has to be differentiable, however there are workarounds for non-differentiable functions such as ReLU. With the derivatives availabe, \emph{gradient descent} can take place. The gradient of the function is calculated and scaled by a (predetermined) \emph{step-size}, before it gets subtracted from the parameter corresponding to the specific entry of the gradient. This process can be executed iteratively which leads to minimizing the function, in the case of NNs the loss function, thereby adjusting the parameters such that the output is closer to the correct output when feeding the network with the same training cases again.